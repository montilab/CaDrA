% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knnmi.R
\name{mutual_inf_cc}
\alias{mutual_inf_cc}
\title{Mutual information estimation MI(X;Y) when the target (X) and features (Y) are continuous.}
\usage{
mutual_inf_cc(target, features, k = 3L)
}
\arguments{
\item{target}{input vector of length N.}

\item{features}{input vector of length N or a matrix of size MxN.}

\item{k}{number of nearest neighbors.}
}
\value{
a double-precision value - mutual information estimation for
vectors \code{target} and \code{features}.
}
\description{
This implements the algorithm described in: 
https://doi.org/10.1103/PhysRevE.69.066138
Alexander Kraskov, Harald Stogbauer, and Peter Grassberger
Phys. Rev. E 69, 066138 ?? Published 23 June 2004; Erratum Phys. Rev. E 83, 019903 (2011)
}
\details{
Compute mutual information of \code{target} and \code{features}
where \code{target} and \code{features} are both continuous
}
\examples{

data(mutual_info_df)
set.seed(654321)
mutual_inf_cc(mutual_info_df$Xc, t(mutual_info_df$Zc_XcYc))
## 0

mutual_inf_cc(mutual_info_df$Yc, t(mutual_info_df$Zc_XcYc))
## 0.2738658

}
