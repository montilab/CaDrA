% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knnmi.R
\name{mutual_inf_cd}
\alias{mutual_inf_cd}
\title{Mutual information estimation MI(X;Y) when the target (X) is continuous and the
features (Y) are discrete.}
\usage{
mutual_inf_cd(target, features, k = 3L)
}
\arguments{
\item{target}{input vector of length N.}

\item{features}{input vector of length N or a matrix of size MxN.}

\item{k}{number of nearest neighbors.}
}
\value{
a double-precision vector - mutual information estimation for
vectors \code{target} and \code{features}.
}
\description{
This implements the algorithm described in:
https://doi.org/10.1371/journal.pone.0087357
Ross BC (2014) Mutual Information between Discrete and Continuous Data Sets. 
PLoS ONE 9(2): e87357.
}
\details{
Compute mutual information of \code{target} and \code{y}
where the \code{target} is continuous and \code{features} are discrete.
}
\examples{

data(mutual_info_df)
set.seed(654321)
mutual_inf_cd(mutual_info_df$Zc_XdYd, t(mutual_info_df$Xd))
## 0.128029

M <- cbind(mutual_info_df$Xd, mutual_info_df$Yd)
mutual_inf_cd(mutual_info_df$Zc_XdYdWd, t(M))
## 0.1070804 0.1041177

}
